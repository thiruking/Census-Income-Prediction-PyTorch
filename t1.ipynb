{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f967f5-ee54-4667-8bb4-31776a45d1da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   age     sex    education  education-num marital-status    workclass  \\\n",
      "0   27    Male      HS-grad              9  Never-married      Private   \n",
      "1   47    Male      Masters             14        Married    Local-gov   \n",
      "2   59    Male      HS-grad              9       Divorced     Self-emp   \n",
      "3   38  Female  Prof-school             15  Never-married  Federal-gov   \n",
      "4   64  Female         11th              7        Widowed      Private   \n",
      "\n",
      "        occupation  hours-per-week income  label  \n",
      "0     Craft-repair              40  <=50K      0  \n",
      "1  Exec-managerial              50   >50K      1  \n",
      "2   Prof-specialty              20  <=50K      0  \n",
      "3   Prof-specialty              57   >50K      1  \n",
      "4  Farming-fishing              40  <=50K      0  \n",
      "Epoch 50/300  Loss: 0.0000\n",
      "Epoch 100/300  Loss: 0.0000\n",
      "Epoch 150/300  Loss: 0.0000\n",
      "Epoch 200/300  Loss: 0.0000\n",
      "Epoch 250/300  Loss: 0.0000\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# 1️⃣ Imports\n",
    "# ============================================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "import random\n",
    "\n",
    "# Random seed for reproducibility\n",
    "SEED = 42\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "\n",
    "# ============================================\n",
    "# 2️⃣ Load Data\n",
    "# ============================================\n",
    "df = pd.read_csv(\"income.csv\")  # adjust path if needed\n",
    "print(df.head())\n",
    "\n",
    "# ============================================\n",
    "# 3️⃣ Identify columns\n",
    "# ============================================\n",
    "label_col = \"income\"   # assume column name is income (<=50K / >50K)\n",
    "cat_cols = [col for col in df.columns if df[col].dtype == \"object\" and col != label_col]\n",
    "cont_cols = [col for col in df.columns if col not in cat_cols + [label_col]]\n",
    "\n",
    "# ============================================\n",
    "# 4️⃣ Encode categorical + label\n",
    "# ============================================\n",
    "label_enc = LabelEncoder()\n",
    "df[label_col] = label_enc.fit_transform(df[label_col])  # 0/1\n",
    "\n",
    "cat_encoders = {}\n",
    "for col in cat_cols:\n",
    "    le = LabelEncoder()\n",
    "    df[col] = le.fit_transform(df[col])\n",
    "    cat_encoders[col] = le\n",
    "\n",
    "# ============================================\n",
    "# 5️⃣ Split train/test\n",
    "# ============================================\n",
    "train_df, test_df = train_test_split(df, train_size=25000, test_size=5000, random_state=SEED)\n",
    "\n",
    "# categorical tensors\n",
    "cat_train = torch.tensor(train_df[cat_cols].values, dtype=torch.long)\n",
    "cat_test  = torch.tensor(test_df[cat_cols].values,  dtype=torch.long)\n",
    "\n",
    "# continuous tensors (scaled)\n",
    "scaler = StandardScaler()\n",
    "cont_train = torch.tensor(scaler.fit_transform(train_df[cont_cols].values), dtype=torch.float)\n",
    "cont_test  = torch.tensor(scaler.transform(test_df[cont_cols].values), dtype=torch.float)\n",
    "\n",
    "# labels\n",
    "y_train = torch.tensor(train_df[label_col].values, dtype=torch.long)\n",
    "y_test  = torch.tensor(test_df[label_col].values, dtype=torch.long)\n",
    "\n",
    "train_ds = TensorDataset(cat_train, cont_train, y_train)\n",
    "test_ds  = TensorDataset(cat_test,  cont_test,  y_test)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=64, shuffle=True)\n",
    "test_loader  = DataLoader(test_ds,  batch_size=64)\n",
    "\n",
    "# ============================================\n",
    "# 6️⃣ Model\n",
    "# ============================================\n",
    "# Embedding sizes\n",
    "embeddings = []\n",
    "for col in cat_cols:\n",
    "    n_unique = df[col].nunique()\n",
    "    emb_size = min(50, (n_unique + 1)//2)\n",
    "    embeddings.append((n_unique, emb_size))\n",
    "\n",
    "class TabularModel(nn.Module):\n",
    "    def __init__(self, emb_dims, n_cont):\n",
    "        super().__init__()\n",
    "        self.emb_layers = nn.ModuleList([nn.Embedding(in_size, out_size) for in_size, out_size in emb_dims])\n",
    "        self.emb_drop = nn.Dropout(0.4)\n",
    "        self.bn_cont  = nn.BatchNorm1d(n_cont)\n",
    "\n",
    "        self.layer1 = nn.Linear(sum(out_size for _, out_size in emb_dims) + n_cont, 50)\n",
    "        self.bn1    = nn.BatchNorm1d(50)\n",
    "        self.drop1  = nn.Dropout(0.4)\n",
    "        self.out    = nn.Linear(50, 2)\n",
    "\n",
    "    def forward(self, x_cat, x_cont):\n",
    "        x = [emb(x_cat[:, i]) for i, emb in enumerate(self.emb_layers)]\n",
    "        x = torch.cat(x, dim=1)\n",
    "        x = self.emb_drop(x)\n",
    "\n",
    "        x_cont = self.bn_cont(x_cont)\n",
    "        x = torch.cat([x, x_cont], dim=1)\n",
    "\n",
    "        x = F.relu(self.bn1(self.layer1(x)))\n",
    "        x = self.drop1(x)\n",
    "        return self.out(x)\n",
    "\n",
    "model = TabularModel(embeddings, len(cont_cols))\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# ============================================\n",
    "# 7️⃣ Training\n",
    "# ============================================\n",
    "for epoch in range(300):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for cat_batch, cont_batch, y_batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        preds = model(cat_batch, cont_batch)\n",
    "        loss = criterion(preds, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    if (epoch+1) % 50 == 0:\n",
    "        print(f\"Epoch {epoch+1}/300  Loss: {total_loss/len(train_loader):.4f}\")\n",
    "\n",
    "# ============================================\n",
    "# 8️⃣ Evaluation\n",
    "# ============================================\n",
    "model.eval()\n",
    "test_loss, correct, total = 0, 0, 0\n",
    "with torch.no_grad():\n",
    "    for cat_batch, cont_batch, y_batch in test_loader:\n",
    "        preds = model(cat_batch, cont_batch)\n",
    "        loss = criterion(preds, y_batch)\n",
    "        test_loss += loss.item()\n",
    "        _, predicted = torch.max(preds, 1)\n",
    "        correct += (predicted == y_batch).sum().item()\n",
    "        total += y_batch.size(0)\n",
    "\n",
    "print(f\"Test Loss: {test_loss/len(test_loader):.4f}\")\n",
    "print(f\"Test Accuracy: {correct/total:.4f}\")\n",
    "\n",
    "# ============================================\n",
    "# 9️⃣ BONUS: Predict function\n",
    "# ============================================\n",
    "def predict_new(sample_dict):\n",
    "    \"\"\"\n",
    "    sample_dict = { 'marital-status': 'Never-married', 'education': 'Bachelors', ... }\n",
    "    \"\"\"\n",
    "    cat_vals = []\n",
    "    cont_vals = []\n",
    "    for c in cat_cols:\n",
    "        val = cat_encoders[c].transform([sample_dict[c]])[0]\n",
    "        cat_vals.append(val)\n",
    "    for c in cont_cols:\n",
    "        val = (sample_dict[c] - scaler.mean_[cont_cols.index(c)]) / scaler.scale_[cont_cols.index(c)]\n",
    "        cont_vals.append(val)\n",
    "\n",
    "    x_cat = torch.tensor([cat_vals], dtype=torch.long)\n",
    "    x_cont = torch.tensor([cont_vals], dtype=torch.float)\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        pred = torch.softmax(model(x_cat, x_cont), dim=1)\n",
    "    return { \"<=50K\": float(pred[0][0]), \">50K\": float(pred[0][1]) }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36319360-9cec-48a0-b926-ca39839246ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
